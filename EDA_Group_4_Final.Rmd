---
title: "Capstone 3 EDA"
author: "Group 4"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    theme: yeti
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

```

```{r packages}
library(lubridate)
library(tidyverse)
library(zoo)
library(ggplot2)
library(melt)
library(reshape2)
library(corrplot)
library(knitr)
library(formattable)
library(kableExtra)
library(gridExtra)
```

# Introductory Section

## Introduction
University of Utah MSBA students Garish Prajapat, Paula Soutostefani, Jade Gosar, and Karson Eilers (subsequently referred to as 'group 4') are assigned to help Maverik use recent store sales data to form a model capable of predicting daily sales volumes for diesel, unleaded gasoline, inside store sales, and food sales. Before we construct a model, we must ascertain a better understanding of the structure and trends in the dataset. This analysis explores the influence of temporal and quantitative variables on sales outcomes as well as examines patterns that may be present within the normal business cycles of Maverik. Additionally, some feature engineering is carried out in preparation of streamlining some inputs to provide better information for the time-series model to learn from. 

## Data Description
Maverik provided group four with two data sets and a list of data definitions for each metric:
<ul>
<li> <strong>time_series_data_msba.csv</strong> contains daily store sales for all four target variables over the 38 stores' respective first years of operation. It also contains opening dates, holidays, day of week, and site ID. There are 12 total variables.</li>
<li> <strong>qualitative_data_msba</strong> contains 53 features of additional operation details for each store. These include a range of information like store layout, fueling station layout, food options, etc.</li>
</ul>


## Key Questions
<ol type="a">
<li> Should the time series be indexed on the day of observation or the number of days since the store opened?</li>
<li> Are there missing observations for any stores? </li>
<li> Should the target variables be evaluated individually or cumulatively? </li>
<li> Are there seasonal trends in the data? </li>
<li> Do the days of the week influence sales of any particular category? </li>
<li> Should all holidays in the dataset be weighted equally? Specifically should "major holiday' be defined as the ones that people are generally given the day off for? This distinguishes "all holidays" which will have noise from less significant holidays. </li>
<li> Should certain days be lagged to understand the effect on sales (e.g., long weekends, vacation around holidays)? </li>
<li> Does the season the store opened in influence their sales? </li>
<li> If what time of the year the store opened does matter, how can we account for the differences in the trends that may be present when projecting daily sales from first day of being open? </li>
<li> How do nearby demographics (number of residents, number of employees, and income) affect store sales? </li>
</ol>


## Missing Data
The data sets provided by Maverik are very tidy and do not appear to contain any missing data. While there are NA values present, these are intentional in that they represent the attribute is not available at that given location. There may be one site discrepancy identified during a Q&A with the project sponsor, but that is anticipated to be addressed soon. 


```{r data import and setup}
#imports qualitative dataset
qual_data <- read.csv("qualitative_data_msba.csv")

#imports time series analysis dataset
raw_ts <- read.csv('time_series_data_msba.csv')

#imports a few key variables from qualitative data set
select_qual <- qual_data %>%
  dplyr::select(
    "site_id_msba",
    "square_feet",
    "parking_spaces",
    "lottery",
    "bonfire_grill",
    "pizza",
    "ethanol_free",
    "hi_flow_lanes",
    "rv_lanes",
    "def",
    "rv_dumps",
  )

#Creates a merged data set, by = site_id_msba by default
merged_df <- merge(raw_ts,select_qual)

#converting characters to factors and rename column that has a row identifier
merged_df <- merged_df %>%
  mutate(across(where(is.character),as.factor)) %>%
  rename("row_id" = "X")

```

# Time Series Dataset Analysis

Group 4 took two general approaches to exploring the time series data. The first is to orient the observations by calendar date. The second approach is to index each site's observations by the number of days that have passed since it opened. 


## Time Series by Calendar Day
Food sales and inside store sales appear to have significant seasonal effects. Those values appear to grow in summer months and decrease into winter months. Unleaded gas and diesel sales show some volatility, but less pronounced seasonal effects. Evaluating target variables by day/month/holiday category or decomposing the time series may indicate a clearer pattern.

```{r mean_day_values, out.width='100%', out.height='100%'}
#mean subset generates an average value for across stores for each given date
mean_subset <- raw_ts %>%
  dplyr::select('calendar.calendar_day_date',
         'diesel','unleaded',
         'daily_yoy_ndt.total_inside_sales',
         'daily_yoy_ndt.total_food_service') %>%
  dplyr::rename('date' = 'calendar.calendar_day_date',
         'inside_sales' = 'daily_yoy_ndt.total_inside_sales',
         'food_sales' = 'daily_yoy_ndt.total_food_service'
         ) %>%
  group_by(date) %>%
   mutate(mean_diesel = mean(diesel),
          mean_unleaded = mean(unleaded),
          mean_inside_sales = mean(inside_sales),
          mean_food_sales = mean(food_sales)
          ) %>%
   dplyr::select('date','mean_diesel', 'mean_unleaded','mean_inside_sales','mean_food_sales') %>%
   unique()

#Lengthens the previous subset and converts target variable categories to types in a new field
lng_avg <- melt(mean_subset, id.vars="date",variable.name="product_type",value.name="average_sales")

# Convert 'date' column to date type
lng_avg$date <- as.Date(lng_avg$date, format = "%m/%d/%Y")

#Creates a faceted line plot by category
ggplot(lng_avg, aes(x=ymd(date), y=average_sales)) + geom_point(color="firebrick2") + facet_grid(~product_type) + scale_x_date(date_labels="%b %Y",
               date_breaks = "4 month",
               guide = guide_axis(angle=45)) +
  labs(title="Sales by Target Variable Category", y = "Average Daily Sales Volume", x = "Date") + geom_smooth(method=loess, color = "black") +
  theme_classic()

```


## Numbered Day Analysis
This approach indexes each observation by the number of days that have passed since the respective store opened. In this approach, the first day that the store is open is given a value of "0" in the created column called "Days_Since_Open". From this point, every day is given a value that is calculated based on the number of days that have passed since the store opened through its first year.

```{r numeric_day_analysis}
#Creates a df using read_csv that handles dates differently
time_series_data <- read_csv("time_series_data_msba.csv", 
    col_types = cols(capital_projects.soft_opening_date = col_date(format = "%m/%d/%Y"), 
        calendar.calendar_day_date = col_date(format = "%m/%d/%Y")))

# Create column that shows the number of days the store has been open
ts_w_days <- time_series_data %>%
  mutate(Days_Since_Open = as.numeric(calendar.calendar_day_date - capital_projects.soft_opening_date)) %>%
  rename("row_id" = "...1") %>%
  arrange(site_id_msba, calendar.calendar_day_date)


# Define the major holidays data frame
major_holidays <- data.frame(
  calendar.calendar_day_date = as.Date(c(
    "2021-01-01", "2021-01-18", "2021-04-04",
    "2021-05-31", "2021-07-04", "2021-09-06", "2021-10-11", "2021-11-11", "2021-11-25", "2021-12-24",
    "2021-12-25", "2021-12-31", "2022-01-01", "2022-01-17",
    "2022-04-17", "2022-05-30", "2022-07-04", "2022-09-05",
    "2022-10-10", "2022-11-11", "2022-11-24",
    "2022-12-24", "2022-12-25", "2022-12-31"
  )),
  Major_Holiday = c(
    "New Year's Day", "Martin Luther King Jr. Day", "Easter Sunday",
    "Memorial Day", "Independence Day", "Labor Day", "Columbus Day",
    "Veterans Day", "Thanksgiving Day", "Christmas Eve", "Christmas Day",
    "New Year's Eve", "New Year's Day", "Martin Luther King Jr. Day",
    "Easter Sunday", "Memorial Day", "Independence Day", "Labor Day",
    "Columbus Day", "Veterans Day", "Thanksgiving Day", "Christmas Eve",
    "Christmas Day", "New Year's Eve"
  )
)

# Merge the original data frame with the major holidays data frame
ts_w_holidays <- ts_w_days %>%
  left_join(major_holidays, by = c("calendar.calendar_day_date" = "calendar.calendar_day_date"))

# Make indicator for whether the day fell on a holiday given by Maverik
ts_all_holidays <- ts_w_holidays %>%
  mutate(General_Holiday = ifelse(calendar_information.holiday == "NONE", 0, 1))
```

## Sales variaton by day of week
There appears to be some clear trends by day of week that span the different target variables. For example, average sales fall on Sunday for each of the individual target variables. 

```{r}
#Creates a day of week summary dataframe 
dow_summary <- ts_all_holidays %>%
  group_by(calendar.day_of_week) %>%
  summarize(Avg_inside_sales = mean(daily_yoy_ndt.total_inside_sales),
            Avg_food_service = mean(daily_yoy_ndt.total_food_service),
            Avg_diesel_sales = mean(diesel),
            Avg_unleaded_sales = mean(unleaded))

# Create the table using kable for better display in html
html_table <- knitr::kable(dow_summary, format = "html")

# Apply kable_styling to adjust column width
day_of_week_summary_table <- kable_styling(html_table, full_width = TRUE)  # Set full_width to TRUE if you want the table to occupy the full width of the page

# Print the day of the week summary table
day_of_week_summary_table
```

```{r, out.width='100%', out.height='100%'}
# Reshape data from wide to long format
data_long <- dow_summary %>%
  pivot_longer(cols = starts_with("Avg_"), names_to = "Sales_Type", values_to = "Average_Sales")

# Order of the days of the week
day_order <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")

# Apply the order to the factor levels
data_long$calendar.day_of_week <- factor(data_long$calendar.day_of_week, levels = day_order)

# Create a line chart with ordered days
line_chart_ordered <- ggplot(data_long, aes(x = calendar.day_of_week, y = Average_Sales, color = Sales_Type, group = Sales_Type)) +
  geom_line(size = 2) +
  labs(title = "Trends in Sales Categories over Days of Week",
       x = "Day of the Week", y = "Average Sales", color = "Sales Type") +
  theme_minimal() +
  theme(legend.position = "top")

# Print the plot
print(line_chart_ordered)
```


The following boxplot for average sales by day of week indicates a slight uptick in sales for Thursday and Friday. There appear to be outliers for each of the estimates that might be partially explained by holiday travel. 

```{r, out.width='100%', out.height='100%'}
# Reorder the factor levels of calendar.day_of_week
ts_all_holidays$calendar.day_of_week <- factor(ts_all_holidays$calendar.day_of_week, levels = day_order)

# Create the boxplot with the ordered days of the week
day_of_week_bp <- ggplot(ts_all_holidays,
  aes(x = calendar.day_of_week, y = unleaded, color = calendar.day_of_week)) +
  geom_boxplot(fill = "white") +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank()) +
  labs(title = "Unleaded Sales tend to be the highest on Fridays", x = "Day of Week", y = "Unleaded Sales") +
  guides(color = FALSE)

# Prints the day of week boxplot
day_of_week_bp
```

## Sales categories variaton over time
To better understand trends of sales for the main categories over the same window of time (from the day the store opened through the first year), we selected four stores that have varying qualitative variables associated with them. Inside and food sales are fairly consistent across the stores selected but there is some variation in unleaded sales and a clear distinction in diesel sales of store 21980 compared to the others. It is more difficult to distinguish the differences in unleaded sales; however, store 22785 seems to experiencing the same seasonal trend but on a different timeline. This finding is how we began to question if we should create a feature that shows what season the store opened in which would allow us to address these potential differences in the modeling process.

```{r, out.width='100%', out.height='100%'}
# Choose stores to highlight their trends over time
selected_stores <- c(21980, 23240, 24150, 22785)
#selected_stores <- c(21560, 22015, 22085, 22120)
#selected_stores <- c(22260, 22330, 22400, 22505)
#selected_stores <- c(22540, 22575, 22645, 22680)
#selected_stores <- c(22715, 22750, 22820, 22855)
#selected_stores <- c(22890, 22925, 23065, 23135)
#selected_stores <- c(23345, 23380, 23415, 23450)
#selected_stores <- c(23485, 23555, 23660, 23730)
#selected_stores <- c(23765, 23835, 23905, 24220, 24535)

# Filter the data to include only the selected stores
stores_of_interest <- ts_all_holidays[ts_all_holidays$site_id_msba %in% selected_stores, ]

#creates a subset of stores of interest
soi_long <- stores_of_interest %>%
  dplyr::select("Days_Since_Open", "site_id_msba", "daily_yoy_ndt.total_inside_sales", "daily_yoy_ndt.total_food_service","diesel","unleaded") %>%
  rename("inside_sales" = "daily_yoy_ndt.total_inside_sales",
         "food_sales" = "daily_yoy_ndt.total_food_service")

#creates a long form of the previous subset
soi_long <- melt(soi_long, id.vars = c("Days_Since_Open","site_id_msba"), variable.name = "product_type", value.name = "average_sales")

#generates a facet plot of the select stores
ggplot(soi_long, aes(x=Days_Since_Open, y=average_sales, group = site_id_msba, color=factor(site_id_msba))) +
  geom_line(size = 1) + facet_wrap(~product_type) + 
  labs(title = "Daily Sales for Selected Stores",
       x = "Number of Days Open",
       y = "Total Sales",
       color = "Store ID") +
  theme_minimal()

```

```{r stores}
#Creates a dataframe with a store-level focus
stores_df <- ts_all_holidays %>%
  dplyr::select("site_id_msba", 
         "diesel", 
         "unleaded", 
         "daily_yoy_ndt.total_inside_sales",
         "daily_yoy_ndt.total_food_service") %>%
  rename("site_id" = "site_id_msba",
         'inside_sales' = 'daily_yoy_ndt.total_inside_sales',
         'food_sales' = 'daily_yoy_ndt.total_food_service'
         )

#Average values for stores
stores_tibble <- stores_df %>%
  group_by(site_id) %>%
  summarize(Avg_Gas= mean(unleaded),
            Avg_Diesel = mean(diesel),
            Avg_Store_Sales = mean(inside_sales),
            Avg_Food_Sales = mean(food_sales))

# Only display the top 10 rows in html output
top_10_rows <- head(stores_tibble, 10)

# Create the table using kable for better display in html
stores_table <- knitr::kable(top_10_rows, format = "html")

# Apply kable_styling to adjust column width
store_averages_table <- kable_styling(stores_table, full_width = TRUE)  # Set full_width to TRUE if you want the table to occupy the full width of the page

# Print the store_averages_table table
store_averages_table
```

## Differences in Holidays and Non-holidays
We think that holidays could be an important consideration to make in the modeling process as days and weekends associated with them could be impactful on sales projections. For this reason we wanted to look at the holidays given by Maverik, which we labeled as "general holidays", compared to non-holidays as well as holidays we deemed as "major holidays", meaning customers generally get the day or days surrounding it off from work or school. The table below shows general holidays tend to have lower sales in all categories when it comes to average and maximum sales compared to regular days; however, there does not appear to be any significant differences that should be investigated further.

```{r}
ts_with_holidays <- ts_all_holidays %>%
  mutate(major_holiday_indicator = ifelse(Major_Holiday == "NA", 0, 1))

holiday_table <- ts_with_holidays %>%
  mutate(General_Holiday = ifelse(General_Holiday == 0, "Not a holiday", "General Holiday")) %>%
  group_by(General_Holiday) %>%
  summarize(`Maximum Unleaded Sales` = max(unleaded),
            `Minimum Unleaded Sales` = min(unleaded),
            `Average Unleaded Sales` = mean(unleaded),
            `Maximum Diesel Sales` = max(diesel),
            `Minimum Diesel Sales` = min(diesel),
            `Average Diesel Sales` = mean(diesel),
            `Maximum Inside Sales` = max(daily_yoy_ndt.total_inside_sales),
            `Average Inside Sales` = mean(daily_yoy_ndt.total_inside_sales),
            `Maximum Food Sales` = max(daily_yoy_ndt.total_food_service),
            `Average Food Sales` = mean(daily_yoy_ndt.total_food_service))

# Create the table using kable for better display in html
holidays <- knitr::kable(holiday_table, format = "html")

# Apply kable_styling to adjust column width
holiday_summary_table <- kable_styling(holidays, full_width = TRUE)  # Set full_width to TRUE if you want the table to occupy the full width of the page

# Print the holiday summary table
holiday_summary_table
```

To better capture how holidays may impact sales at Maverik, we decided to narrow the scope by distinguishing major holidays from general holidays. The below table shows larger differences when distinguishing major holidays from the rest of the business days, meaning that sales, on average, tend to be lower across all categories when it is a major holiday compared against general holidays and regular business days.  

```{r}
major_holiday_table <- ts_with_holidays %>%
  mutate(major_holiday_indicator = ifelse(major_holiday_indicator == 1, "Major Holiday", "")) %>%
  group_by(major_holiday_indicator) %>%
  summarize(`Maximum Unleaded Sales` = max(unleaded),
            `Minimum Unleaded Sales` = min(unleaded),
            `Average Unleaded Sales` = mean(unleaded),
            `Maximum Diesel Sales` = max(diesel),
            `Minimum Diesel Sales` = min(diesel),
            `Average Diesel Sales` = mean(diesel),
            `Maximum Inside Sales` = max(daily_yoy_ndt.total_inside_sales),
            `Average Inside Sales` = mean(daily_yoy_ndt.total_inside_sales),
            `Maximum Food Sales` = max(daily_yoy_ndt.total_food_service),
            `Average Food Sales` = mean(daily_yoy_ndt.total_food_service)) %>%
  rename("Type of Day" = major_holiday_indicator)

# Replace NA with "Normal Business Day" in the table
major_holiday_table$`Type of Day` <- ifelse(is.na(major_holiday_table$`Type of Day`), "Normal Business Day", major_holiday_table$`Type of Day`)

# Create the table using kable for better display in html
major_holidays <- knitr::kable(major_holiday_table, format = "html")

# Apply kable_styling to adjust column width
major_holidays_summary_table <- kable_styling(major_holidays, full_width = TRUE)  # Set full_width to TRUE if you want the table to occupy the full width of the page

# Print the major holiday summary table
major_holidays_summary_table
```

```{r}
# Create the density plot for Food Service Sales
food_service_plot <- ggplot(ts_with_holidays, aes(x = daily_yoy_ndt.total_food_service, fill = as.factor(`major_holiday_indicator`))) +
  geom_density(alpha = 0.6) +
  labs(title = "Food Service Sales Distributions", x = "Sales", fill = "Type of Day") +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank()) +
  scale_fill_manual(values = c("#CC0000", "#C1CDCD"), 
                    labels = c("Major Holiday", "Not a holiday"))

# Create the density plot for Inside Sales
inside_sales_plot <- ggplot(ts_with_holidays, aes(x = daily_yoy_ndt.total_inside_sales, fill = as.factor(`major_holiday_indicator`))) +
  geom_density(alpha = 0.6) +
  labs(title = "Inside Sales Distributions", x = "Sales", fill = "Type of Day") +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank()) +
  scale_fill_manual(values = c("#CC0000", "#C1CDCD"), 
                    labels = c("Major Holiday", "Not a holiday"))

# Create the density plot for Diesel Gallons Sold
diesel_gallons <- ggplot(ts_with_holidays, aes(x = diesel, fill = as.factor(`major_holiday_indicator`))) +
  geom_density(alpha = 0.6) +
  labs(title = "Diesel Gallons Sold Distributions", x = "Gallons", fill = "Type of Day") +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank()) +
  scale_fill_manual(values = c("#CC0000", "#C1CDCD"), 
                    labels = c("Major Holiday", "Not a holiday"))

# Create the density plot for Unleaded Gallons Sold
unleaded_gallons <- ggplot(ts_with_holidays, aes(x = unleaded, fill = as.factor(`major_holiday_indicator`))) +
  geom_density(alpha = 0.6) +
  labs(title = "Unleaded Gallons Sold Distributions", x = "Gallons", fill = "Type of Day") +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank()) +
  scale_fill_manual(values = c("#CC0000", "#C1CDCD"), 
                    labels = c("Major Holiday", "Not a holiday"))

# Display all plots in one visualization
grid.arrange(food_service_plot, inside_sales_plot, diesel_gallons, unleaded_gallons, ncol = 2)

```

The above visualization confirms that major holidays may negatively affect business at Maverik, at least on the actual day of the holiday. We plan to explore this relationship further in the modeling process through feature engineering that will allow us to see if the days surrounding these holidays have an impact that lessens or exacerbates the impact holidays have on the business.

## Data Distributions

Fuel sales are measured in gallons sold while inside store sales and food service sales are measured in dollars. We will compare the distribution of each set of target variables based on their scale. The daily sales data for fuel appears to be similarly distributed. Diesel sales values skew farther to the left than unleaded gasoline sales. 

```{r fuel_sales_distro}
#Data distribution for both types of fuel sales.
raw_ts %>%
  dplyr::select("diesel", 
         "unleaded", ) %>%
  melt(variable.name = "product_type", value.name = "sales") %>%
  ggplot(aes(x=sales, color=product_type)) + geom_histogram(fill="white", position="dodge") + labs(title="Daily Sales Distribution by Product Category", x = "Daily Sales")

```

The daily inside sales values distributions look for varied. Food sales values are fairly concentrated around the $1,000 values. Inside sales, on the other hand, appears more normally distributed.

```{r inside_sales_distro}
#Data distribution for both types of inside store sales.
raw_ts %>%
  dplyr::select("daily_yoy_ndt.total_inside_sales",
         "daily_yoy_ndt.total_food_service") %>%
  rename('inside_sales' = 'daily_yoy_ndt.total_inside_sales',
         'food_sales' = 'daily_yoy_ndt.total_food_service'
         ) %>%
  melt(variable.name = "product_type", value.name = "sales") %>%
  ggplot(aes(x=sales, color=product_type)) + geom_histogram(fill="white", position="dodge") + labs(title="Daily Sales Distribution by Product Category", x = "Daily Sales")

```

# Qualitative Variables

## Store Layout
Store layouts vary by some measures more than others. For example, the largest stores have nearly double the square feet and parking spaces as smaller stores. About 62.2% of stores sell lottery tickets. This might be interpreted as an indicator as to whether stores that are in Utah or not.

```{r store_layout}
# Summarizes store layout values
qual_data %>%
  dplyr::select("square_feet",
         "parking_spaces",
         "lottery"
         ) %>%
  mutate(lottery = as.factor(lottery)) %>%
  summary()

```

Three of the five qualitative variables pertaining to food products (freal, cinnabon, and godfather's pizza) are nearly uniform in the data set. Bonfire grill products and pizza do vary more by store. 

```{r food_options}
# Summarizes qual data food variables
qual_data %>%
  dplyr::select("freal",
         "bonfire_grill",
         "pizza",
         "cinnabon",
         "godfather_s_pizza"
         ) %>%
  mutate_all(as.factor) %>%
  summary()

```

## Fuel Pumps

```{r fuel_pumps}
# Summarizes qual data related to fuel stations
qual_data %>%
  dplyr::select("ethanol_free",
         "diesel",
         "hi_flow_lanes",
         "rv_lanes",
         "hi_flow_rv_lanes"
         ) %>%
  mutate_all(as.factor) %>%
  summary()

```

## Gas Station Amenities

```{r amenities}
# Summarizes qual data related to fuel stations
qual_data %>%
  dplyr::select("def",
         "cat_scales",
         "car_wash",
         "ev_charging",
         "rv_dumps",
         "propane"
         ) %>%
  mutate_all(as.factor) %>%
  summary()
```

## Nearby store demographics
There are three demographic metrics in the qualitative data set: population residing, population employed, and median income. There are four measures of proximity for each of these factors: 1/2 mile, 1 mile, 5 minutes, and 7 minutes. The inclusion of both miles and minutes is presumably to account for locations situated in commercial areas or near highways/freeways where nearby customers have quick access but may be a longer geographic distance. We presume that there is likely some hidden collinearity within these metrics so we prefer to select the measure that has the greatest effect on sales. Since we have four outcome variables, we compare correlation with each using a correlation heatmap.

There does not appear to be significant correlation between these demographic metrics and the target variables.

```{r demographics_Mile}
demo_values <- read.csv("qualitative_data_msba.csv")
ts_import <- read.csv("time_series_data_msba.csv")

demo_values_merged <- merge(ts_import, demo_values, by="site_id_msba")

demo_values <- demo_values_merged%>%
  dplyr::select("site_id_msba",
         "x1_mile_pop",
         "x1_mile_emp",
         "x1_mile_income",
         "x1_2_mile_pop",
         "x1_2_mile_emp",
         "x1_2_mile_income",
         "x5_min_pop",
         "x5_min_emp",
         "x5_min_inc",
         "x7_min_pop",
         "x7_min_emp",
         "x7_min_inc",
         "unleaded",
         "diesel.x",
         "daily_yoy_ndt.total_inside_sales",
         "daily_yoy_ndt.total_food_service"
  ) %>% rename('inside_sales' = 'daily_yoy_ndt.total_inside_sales',
         'food_sales' = 'daily_yoy_ndt.total_food_service'
         )

demo_values <- demo_values[2:17]

demo_values.cor <- cor(demo_values)

corrplot(demo_values.cor)
```

Beyond the correlation values, we can intuit that a wider radius would generally increase both the estimates and variation for each of these values. Plotting four different measures of population confirms this. 

```{r pop}
# Creates a boxplot for different population measures
read.csv("qualitative_data_msba.csv") %>%
  dplyr::select("site_id_msba",
         "x1_2_mile_pop",
         "x1_mile_pop",
         "x5_min_pop",
         "x7_min_pop"
         ) %>%
  rename("x1/2_mile_pop"="x1_2_mile_pop") %>%
  melt(id.vars="site_id_msba", variable.name="population_measure", value.name="population") %>%
  mutate(population_measure = as.factor(population_measure)) %>%
  ggplot(aes(y=population, x=population_measure)) + geom_boxplot() + labs(title="Population Near Store Sites by Measurement Category", x="Measure of Population", y = "Population")

```




# Conclusion and Results Section

## Results
The two data sets provided by Maverik are both very clean so we do not anticipate running into issues with missing values or incomplete data for the stores. The only data problem that we foresee having an impact will be due to the smaller sample size and our group only having access to information on 37 stores. While this is absolutely sufficient, there may be less variability than we would like in some of the features which may not give our model enough information to learn the nuances within the dataset. We plan to use simulation to potentially help combat this problem if it arises in the modeling phase. As for other ways our EDA has influenced our analytical approach, we now have a better understanding for what features we can and should engineer to better illustrate similarities and differences among the stores that can be used to more accurately predict the sales figures. It also has informed our decision making pertaining to implementing a standardized way to compare the stores based on the number of days they have been open. This ensures that we will be look at trends as they relate to the expected business cycles of the store and identify if there are any differences to be expected based on what time of year the store opens or what time point they are at within their first year. While we may not currently know exactly what model will perform the best on the data once we have completed all feature engineering, our EDA has allowed us to gain important initial insights into what types of variables may be important to consider in the modeling process.

Our initial exploration into the data has led us to believe that the temporal effects (e.g., day of week, seasonality, and length of time since opening) seem to have a greater effect on the target variables than most of the qualitative variables do. For this reason, we plan on having to specify different qualitative variables for different target variables in the modeling process. This was a key takeaway from our EDA portion of the project because, as our visualization that shows trends over time for only a couple stores indicates, there can be vast differences in the sales of one of the categories for a singular store while the other sales categories experience very similar trends when being compared across stores. All in all, this means that we plan to personalize our model's predictions as much as possible to better represent each of the sales categories by treating them separately and distinguishing important relationships that may not be present if looking at the sales figures on an aggregate level. Another interesting relationship from the temporal analyses that was worth noting is was how sales in all categories seems to follow the same trend throughout the week, with average sales typically falling through the weekend compared to their peak on Friday. Other relationships that seem particularly strong are holidays, in the fact that Maverik tends to have lower average sales on holidays labeled as "major" by the team, meaning that businesses and schools are closed for the day. Additionally, there is demographic information and varying store layouts that could provide valuable information on qualitative attributes that have a relationship with the target variables of the four sales categories. Overall, we plan to add all of these considerations into our model, allowing us to represent the relationships our initial analysis has indicated could potentially be significant in predicting more accurate sales figured for newly opened Maverik stores.

## Group Contributions
Karson Eilers: Analyzed the target variables by date, the target variable distributions, gas station layout sections, and the nearby store demographics. He drafted the introduction section as well as the initial document and the summary descriptions for several of the graphs. Lastly, he aggregated the two data sources together to be used in modeling and explored potential multicollinearity in the dataset, particularly in the demographic information.

Paula Soutostefani: Focused on doing exploratory graphs for different relationships between the qualitative dataset variables and the four main time series target variables (food sales, inside sales, gas and diesel). Her focus was in identifying possible impacts and effects of holidays in the four main variables, and the differences in sales amounts between holiday periods and non-holiday periods.

Garish Prajapat: Worked on finalizing the EDA document and making sure all rubric requirements were met.

Jade Gosar: Took the lead on aggregating all group member's data into the final submission document, made sure code was annotated and outputs were interpreted, and wrote the conclusion section. She performed the initial feature engineering by creating the column to track days since the store opened, the indicators for whether a given holiday was major or general, and the visualizations relating to sales trends over time.
